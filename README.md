
# ğŸ•µï¸ Web Research AI Agent

This project is a **Web Research AI Agent** that integrates multiple tools such as web search, scraping, news summarization, and content analysis using LLMs. Built with **FastAPI**, **Streamlit**, and **LangChain**, this app enables users to ask complex queries and receive intelligent, structured responses.

---

## ğŸ› ï¸ Features

- ğŸŒ **Web Search** â€“ Search the web using DuckDuckGo.
- ğŸ“° **News Aggregation** â€“ Fetch and summarize latest news articles.
- ğŸ§  **Content Analyzer** â€“ Detect sentiment, topics, and bias in text.
- ğŸ” **Web Scraper** â€“ Scrape and extract text content from URLs.
- ğŸ§© **LangChain Integration** â€“ Modular agent with tool-based reasoning.
- ğŸ¨ **Streamlit UI** â€“ Chat-like interface for asking questions.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ api.py                         # FastAPI main backend entry
â”œâ”€â”€ app.py                         # Streamlit frontend app
â”œâ”€â”€ api_endpoints/                # FastAPI endpoints for tools
â”‚   â”œâ”€â”€ analyze.py
â”‚   â”œâ”€â”€ news.py
â”‚   â”œâ”€â”€ scraper.py
â”‚   â””â”€â”€ web_search.py
â”œâ”€â”€ contentwrapper.py             # Wrapper and tool for content analysis
â”œâ”€â”€ news_wrapper.py               # Wrapper and tool for news summaries
â”œâ”€â”€ scraping.py                   # Wrapper and tool for scraping URLs
â”œâ”€â”€ search_wrapper.py             # Wrapper and tool for web search
â”œâ”€â”€ gpt_utils.py                  # Tool setup for agent
â”œâ”€â”€ prompt.py                     # LangChain hub prompt loader
â”œâ”€â”€ .env                          # Environment variables
â””â”€â”€ requirements.txt              # Python dependencies
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/venkatavinayvijjapu/New_Assignment.git
cd web-research-agent
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

> Make sure you have Python 3.9 or later.

### 3. Setup Environment Variables

Create a `.env` file in the root directory and add the following:

```env
GEMINI_API_KEY=your_google_gemini_api_key
GROQ_API_KEY=your_groq_api_key
```

---

## ğŸ§ª Running the Project

### 1. Start the FastAPI Backend

```bash
uvicorn api:app --reload
```

This will run the FastAPI server at `http://127.0.0.1:8000`

You can test endpoints like:

- `POST /analyze_content`
- `POST /web_search`
- `POST /scrape_url`
- `POST /news_summary`

### 2. Launch the Streamlit Frontend

Open a new terminal window and run:

```bash
streamlit run app.py
```

This starts the frontend interface at `http://localhost:8501`.

---

## ğŸ§­ Flow of Execution

1. **Streamlit UI (`app.py`)** is loaded and tools are initialized:
   - Web Search Tool
   - Scraper Tool
   - News Aggregator Tool
   - Content Analyzer Tool

2. **User inputs a question** in the chat interface.

3. **LangChain Agent** is created using:
   - `create_openai_tools_agent` from LangChain
   - LLM: `llama-3.3-70b-versatile` via GROQ API

4. **Agent parses the query**, selects the relevant tool(s) and invokes the backend API using:
   - `requests` calls defined in wrapper classes

5. **FastAPI Endpoint** processes the request (e.g. fetches data, analyzes text using Gemini API, scrapes web pages).

6. **Response is returned** to the user as a markdown message in the chat.

---

## ğŸ” API Integration Details

- **Google Gemini API** â€“ Used in `analyze.py` for content analysis.
- **GROQ LLM API** â€“ Used via `ChatGroq` to power the LangChain agent.

---

## ğŸ§ª Example Usage

- â€œSummarize recent news about electric vehicles.â€
- â€œScrape this article and analyze it for bias: https://example.com/articleâ€
- â€œSearch the web for the latest on quantum computing.â€
- â€œAnalyze this paragraph for sentiment.â€

---

## ğŸ“ˆ Metrics

The backend is instrumented using `prometheus_fastapi_instrumentator`. Visit `/metrics` on the FastAPI server to see real-time metrics.

